{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9175a8e",
   "metadata": {},
   "source": [
    "#### Start by creating a directory with the name of the desired country followed by a date (e.g., nigeria2016)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26182e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the country name\n",
    "country = 'nigeria2016'\n",
    "\n",
    "# Check if the directory already exists\n",
    "if not os.path.exists(country):\n",
    "    # Create the directory if it doesn't exist\n",
    "    os.makedirs(country)\n",
    "    print(f\"Directory '{country}' created.\")\n",
    "else:\n",
    "    print(f\"Directory '{country}' already exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141327f5",
   "metadata": {},
   "source": [
    "#### Create and add `acled.csv` file in the created directory (e.g., nigeria2016).\n",
    "\n",
    "For more information, visit https://flee.readthedocs.io/en/master/Simulation_instance_construction/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fc4cbc",
   "metadata": {},
   "source": [
    "#### This builder extracts cities/towns populations from an HTML file and stores it in the population.csv file. \n",
    "\n",
    "The desired country can be found by searching the https://www.citypopulation.de/ site (e.g., https://www.citypopulation.de/en/nigeria/cities/).\n",
    "\n",
    "Store the webpage \"CTRL+S\" as an HTML file (e.g., population.html) and place in in the created directory.\n",
    "\n",
    "The builder accesses the tables in HTML file and extract data from a specified table (e.g., table[0], table[1]). Specify the table in the code \"line 19\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676f72f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# This also becomes the name of the directory where files are stored.\n",
    "country = 'nigeria2016'\n",
    "\n",
    "html_file = '{}/population.html'.format(country, country)\n",
    "\n",
    "if os.path.isfile(html_file):\n",
    "    tables = pd.read_html(html_file)\n",
    "    # Continue with further processing of the tables\n",
    "else:\n",
    "    print(\"The file '{}' is not found.\".format(html_file))\n",
    "\n",
    "# Uncomment to make sure the tables are accessed from the html file\n",
    "# print(tables)\n",
    "\n",
    "# Specify table with major cities' names and population\n",
    "table = tables[0]\n",
    "\n",
    "# Uncomment to make sure the desired table is accessed from tables\n",
    "# print(table)\n",
    "\n",
    "# Please make sure the column names exist in the specified table\n",
    "selected_columns = table[['Name', 'Population Census (Cf) 2006-03-21']]\n",
    "\n",
    "# Drop rows with missing values in the selected columns\n",
    "selected_columns = selected_columns.dropna()\n",
    "\n",
    "# Rename columns\n",
    "selected_columns.columns = ['name', 'population']\n",
    "\n",
    "# Filter rows with population greater than 10,000\n",
    "selected_columns = selected_columns[selected_columns['population'] > 10000]\n",
    "\n",
    "# Save the data to a CSV file\n",
    "output_file = '{}/population.csv'.format(country)\n",
    "selected_columns.to_csv(output_file, index=False)\n",
    "\n",
    "print(f'{country}/population.csv created. Please inspect the file for non-standard characters!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c97f02",
   "metadata": {},
   "source": [
    "#### This builder extracts locations using acled.csv and created population.csv files, and stores them in locations.csv file. \n",
    "\n",
    "Set the conflict_threshold to only assign conflict zones to location types with conflict periods greater than the threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48110d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import sys\n",
    "import os\n",
    "import calendar as cal\n",
    "from datetime import datetime\n",
    "import json\n",
    "import requests\n",
    "import time\n",
    "import wikipedia\n",
    "import wbdata\n",
    "\n",
    "def date_format(in_date):\n",
    "    # converting date from textbased to dd-mm-yyyy format\n",
    "    if \"-\" in in_date:\n",
    "        split_date = in_date.split(\"-\")\n",
    "    else:\n",
    "        split_date = in_date.split(\" \")\n",
    "\n",
    "    month_num = month_convert(split_date[1])\n",
    "    if int(split_date[2]) < 50:\n",
    "        year = int(split_date[2]) + 2000\n",
    "    else:\n",
    "        year = int(split_date[2])\n",
    "    out_date = split_date[0] + \"-\" + str(month_num) + \"-\" + str(year)\n",
    "    return out_date\n",
    "\n",
    "def month_convert(month_name):\n",
    "    months = {\n",
    "    \"jan\": \"01\", \"january\": \"01\",\n",
    "    \"feb\": \"02\", \"february\": \"02\",\n",
    "    \"mar\": \"03\", \"march\": \"03\",\n",
    "    \"apr\": \"04\", \"april\": \"04\",\n",
    "    \"may\": \"05\", \"may\": \"05\",\n",
    "    \"jun\": \"06\", \"june\": \"06\",\n",
    "    \"jul\": \"07\", \"july\": \"07\",\n",
    "    \"aug\": \"08\", \"august\": \"08\",\n",
    "    \"sep\": \"09\", \"september\": \"09\",\n",
    "    \"oct\": \"10\", \"october\": \"10\",\n",
    "    \"nov\": \"11\", \"november\": \"11\",\n",
    "    \"dec\": \"12\", \"december\": \"12\"\n",
    "    }\n",
    "\n",
    "    # Convert the month name to lowercase and strip leading/trailing whitespace\n",
    "    month_name = month_name.strip().lower()\n",
    "\n",
    "    # Look up the month number in the dictionary\n",
    "    if month_name in months:\n",
    "        month_num = months[month_name]\n",
    "        #print(f\"The month number for {month_name} is {month_num}.\")\n",
    "    else:\n",
    "        print(\"Invalid month name entered.\")\n",
    "\n",
    "    return month_num\n",
    "\n",
    "def between_date(d1, d2):\n",
    "    # Gets difference between two dates in string format \"dd-mm-yyyy\"\n",
    "    d1list = d1.split(\"-\")\n",
    "    d2list = d2.split(\"-\")\n",
    "    date1 = datetime(int(d1list[2]), int(d1list[1]), int(d1list[0]))\n",
    "    date2 = datetime(int(d2list[2]), int(d2list[1]), int(d2list[0]))\n",
    "\n",
    "    return abs((date1 - date2).days)  # Maybe add +1\n",
    "\n",
    "def drop_rows(inputdata, columnname, dropparameter):\n",
    "    removedrows = inputdata.index[\n",
    "        inputdata[columnname] <= dropparameter].tolist()\n",
    "    outputdata = inputdata.drop(removedrows)\n",
    "    return outputdata\n",
    "\n",
    "def get_state_population(state_name, population_input_file):\n",
    "    df = pd.read_csv(population_input_file)\n",
    "    filtered_df = df[df['name'] == state_name]\n",
    "    if len(filtered_df) > 0:\n",
    "        population = filtered_df['population'].values[0]\n",
    "        return population\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_city_population(city_name,population_input_file):\n",
    "    country_code = 'ML'\n",
    "    url = \"https://wft-geo-db.p.rapidapi.com/v1/geo/cities/{0}\".format(get_wikidata_id(city_name))\n",
    "\n",
    "    headers = {\n",
    "        \"X-RapidAPI-Key\": \"6e1b07b54fmsh14df87e58d9db7bp175272jsn85fd0398365f\",\n",
    "        \"X-RapidAPI-Host\": \"wft-geo-db.p.rapidapi.com\"\n",
    "    }\n",
    "    response = requests.request(\"GET\", url, headers=headers)\n",
    "\n",
    "    if response.status_code == 404:\n",
    "        get_state_population(city_name,population_input_file)\n",
    "\n",
    "    else:\n",
    "        data = response.json()\n",
    "        population = data[\"data\"]['population']\n",
    "        return population\n",
    "    \n",
    "def filter_table(df, colname, adminlevel):\n",
    "    if adminlevel == \"admin1\":\n",
    "        adminlist = df.admin1.unique()\n",
    "    elif adminlevel == \"location\":\n",
    "        adminlist = df.location.unique()\n",
    "    else:\n",
    "        adminlist = df.admin2.unique()\n",
    "\n",
    "    newdf = pd.DataFrame()  \n",
    "\n",
    "    for admin in adminlist:\n",
    "        tempdf = df.loc[df[adminlevel] == admin]\n",
    "        tempdf.sort_values(colname, ascending=True)\n",
    "        newdf = pd.concat([newdf, tempdf.tail(1)])\n",
    "\n",
    "    return newdf\n",
    "\n",
    "\n",
    "def acled2locations(country, start_date, filter_opt, location_type=\"admin1\", conflict_threshold=100):\n",
    "    current_dir = os.getcwd()\n",
    "    input_file = os.path.join(current_dir, country, \"acled.csv\") \n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(input_file)\n",
    "    except:\n",
    "        print(\"Runtime Error: File Cannot be found\")\n",
    "        return\n",
    "    \n",
    "    df = df[[\"event_date\", \"country\", \"admin1\", \"admin2\", \"location\", \"latitude\", \"longitude\", \"event_type\", \"sub_event_type\", \"fatalities\"]]\n",
    "    \n",
    "    event_dates = df[\"event_date\"].tolist()\n",
    "    \n",
    "    formatted_event_dates = [date_format(date) for date in event_dates]\n",
    "    \n",
    "    # Calculate the number of days between each event's date and the start_date\n",
    "    conflict_dates = [between_date(d, start_date) for d in formatted_event_dates]\n",
    "    \n",
    "    # Add days to the df\n",
    "    df['conflict_date'] = conflict_dates\n",
    "    \n",
    "    # Including all events\n",
    "    fatalities_threshold = 0\n",
    "    \n",
    "    # Dropping rows based on the 'fatalities_threshold'    \n",
    "    df = drop_rows(df, 'fatalities', fatalities_threshold)\n",
    "    \n",
    "    # Sorting the df by 'conflict_date' and 'admin1' and drops duplicate rows\n",
    "    df = df.sort_values([\"conflict_date\", \"admin1\"]).drop_duplicates([\"conflict_date\", \"admin1\"])\n",
    "    \n",
    "    if filter_opt == 'earliest':\n",
    "        filter_opt = 'conflict_date'\n",
    "\n",
    "    try:\n",
    "        df = filter_table(df, filter_opt, location_type)\n",
    "    except:\n",
    "        print(\"Runtime error: filter_opt value must be earliest or fatalities\")\n",
    "        \n",
    "    output_df = df[['admin1', 'country', 'latitude', 'longitude', 'conflict_date']]\n",
    "    \n",
    "    output_df.columns = ['name', 'country', 'latitude', 'longitude', 'conflict_date'] \n",
    "    \n",
    "    # Create two DataFrames for towns and conflict zones\n",
    "    towns_df = df[df['conflict_date'] <= conflict_threshold].copy()\n",
    "    conflict_zones_df = df[df['conflict_date'] > conflict_threshold].copy()\n",
    "    \n",
    "    # Assign location types\n",
    "    towns_df['location_type'] = 'town'\n",
    "    conflict_zones_df['location_type'] = 'conflict_zone'\n",
    "    \n",
    "    # Merge the DataFrames back together if necessary\n",
    "    merged_df = pd.concat([towns_df, conflict_zones_df])\n",
    "    \n",
    "    # Create a dictionary to store location names from population.csv as keys and their populations as values\n",
    "    population_dict = {row['name']: row['population'] for index, row in population_df.iterrows()}\n",
    "    \n",
    "    # Add population to the merged_df based on 'admin1' names\n",
    "    merged_df['population'] = [population_dict.get(name, 0) for name in merged_df['admin1']]\n",
    "    \n",
    "    # Replace any infinite or NaN values with 0 and convert population to integers\n",
    "    merged_df['population'] = merged_df['population'].replace([np.inf, -np.inf, np.nan], 0)\n",
    "    merged_df['population'] = merged_df['population'].astype(int)\n",
    "    \n",
    "    # Reorder columns and rename them\n",
    "    merged_df = merged_df[['admin1', 'country', 'latitude', 'longitude', 'location_type', 'conflict_date', 'population']]\n",
    "    merged_df.columns = ['name', 'country', 'latitude', 'longitude', 'location_type', 'conflict_date', 'population']\n",
    "\n",
    "    # Save the final 'locations.csv' file\n",
    "    output_file = os.path.join(country, \"locations.csv\")\n",
    "    merged_df.to_csv(output_file, index=False)\n",
    "\n",
    "    print(f'{country}/locations.csv created. Please inspect the file for unwanted anomalies!')\n",
    "\n",
    "    \n",
    "# Please replace the country name \n",
    "country = \"nigeria2016\"\n",
    "start_date = \"01-01-2016\"\n",
    "filter_opt = 'earliest'\n",
    "location_type = \"admin1\"\n",
    "conflict_threshold = 100\n",
    "\n",
    "population_input_file = os.path.join(country, \"population.csv\")\n",
    "\n",
    "acled2locations(country, start_date, filter_opt, location_type=\"admin1\", conflict_threshold=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2238a5c",
   "metadata": {},
   "source": [
    "#### This builder constructs conflicts.csv from created locations.csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f4da97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "# Replace path with the actual directory path\n",
    "flee_path = '/home/mghorbani/workspace/flee'\n",
    "sys.path.append(flee_path)\n",
    "\n",
    "# Now you can import the modules from the 'flee' package\n",
    "from flee.InputGeography import InputGeography\n",
    "\n",
    "def find_column_index(header, column_name):\n",
    "    # Find the index of a column by matching its name in the header\n",
    "    for i, col in enumerate(header):\n",
    "        if col == column_name:\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "def location2conflict(simulation_period, input_file, output_file):\n",
    "    ig = InputGeography()\n",
    "    ig.ReadLocationsFromCSV(input_file)\n",
    "\n",
    "    with open(input_file, \"r\") as file:\n",
    "        reader = csv.reader(file)\n",
    "        header = next(reader)\n",
    "        conflict_zone_index = find_column_index(header, \"location_type\")\n",
    "        conflict_date_index = find_column_index(header, \"conflict_date\")\n",
    "\n",
    "    # Create the header string for the output file without the \"name\" column\n",
    "    output_header_string = \"day\"\n",
    "    for l in ig.locations:\n",
    "        if l[conflict_zone_index] == \"conflict_zone\":\n",
    "            output_header_string += \",%s\" % l[0]\n",
    "    output_header_string += \"\\n\"\n",
    "\n",
    "    with open(output_file, \"w\") as file:\n",
    "        file.write(output_header_string)\n",
    "\n",
    "        for t in range(0, simulation_period):\n",
    "            output = \"%s\" % t\n",
    "            for l in ig.locations:\n",
    "                if l[conflict_zone_index] == \"conflict_zone\":\n",
    "                    confl_date = int(l[conflict_date_index])\n",
    "                    if confl_date <= t:\n",
    "                        output += \",1\"\n",
    "                    else:\n",
    "                        output += \",0\"\n",
    "            output += \"\\n\"\n",
    "            file.write(output)\n",
    "\n",
    "\n",
    "# Set the values for simulation_period, input_file, and output_file\n",
    "simulation_period = 365\n",
    "\n",
    "# Please specify a country name\n",
    "country = \"nigeria2016\"\n",
    "\n",
    "input_file = os.path.join(country, \"locations.csv\")\n",
    "\n",
    "output_file = os.path.join(country, \"conflicts.csv\")\n",
    "\n",
    "# Call the function location2conflict\n",
    "location2conflict(simulation_period, input_file, output_file)\n",
    "\n",
    "print(f'{country}/conflicts.csv created.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174bcfe1",
   "metadata": {},
   "source": [
    "####  This builder simulates forcasting conflict data in a given country and visualising it using custom distribution functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a365ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date\n",
    "\n",
    "# Read \n",
    "def read_conflict_zones(filename):\n",
    "    try:\n",
    "        df = pd.read_csv(filename)\n",
    "        conflict_zones = df.columns[1:].tolist()\n",
    "        conflict_zones = [zone for zone in conflict_zones if zone]  # Exclude empty headers\n",
    "        return conflict_zones\n",
    "    except FileNotFoundError:\n",
    "        print(\"File not found: \", filename)\n",
    "        return []\n",
    "    \n",
    "    \n",
    "# Custom function to generate all zeros csv file\n",
    "def generate_conflict_zones_csv(filename, conflict_zones, period):\n",
    "    data = {'Days': list(range(period))}\n",
    "    data.update({zone: [0] * period for zone in conflict_zones})\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(filename, index=False)\n",
    "    \n",
    "\n",
    "# Custom distribution function\n",
    "def custom_distribution(intensity, x):\n",
    "    max_value = intensity\n",
    "    peak_day = 365\n",
    "    std_deviation = 800\n",
    "    variation_factor = 0.01  # Adjust the variation factor as desired\n",
    "    \n",
    "    spreading_factor = np.exp(-((x - peak_day) / std_deviation) ** 2)\n",
    "    \n",
    "    # Add random fluctuations to the spreading factor\n",
    "    spreading_factor += np.random.normal(0, variation_factor, len(x))\n",
    "    \n",
    "    y = max_value * spreading_factor\n",
    "    return y\n",
    "\n",
    "# Specify the simulation country\n",
    "country = 'nigeria2016'\n",
    "\n",
    "# Create the path to input file\n",
    "input_file = os.path.join(country, 'conflicts.csv')\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Call the function to extract the conflict_zones from the file\n",
    "conflict_zones = read_conflict_zones(input_file)\n",
    "\n",
    "# Set the intensity as maximum number of conflict zones \n",
    "intensity = len(conflict_zones)\n",
    "\n",
    "# Generate x-axis values\n",
    "start_date = date(2016, 1, 1)\n",
    "current_date = date(2016, 12, 31)\n",
    "days_passed = (current_date - start_date).days\n",
    "\n",
    "# Specify the simulation period for forcasting\n",
    "period = days_passed * 2\n",
    "\n",
    "# Generate x-axis values using a custom_distributions\n",
    "x1 = np.linspace(0, days_passed, num=days_passed).astype(int)\n",
    "x2 = np.linspace(days_passed, period, num=period - days_passed).astype(int)\n",
    "\n",
    "# Generate y-axis values using conflicts values\n",
    "y1 = df.iloc[:, 1:days_passed + 1].sum(axis=1)[:days_passed]\n",
    "\n",
    "# Generate y-axis values using a custom_distribution\n",
    "y2 = custom_distribution(intensity, x2)\n",
    "\n",
    "# Combine the generated data\n",
    "x = np.concatenate((x1, x2))\n",
    "y = np.concatenate((y1, y2))\n",
    "\n",
    "# Create subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "\n",
    "# Plot graph\n",
    "ax1.plot(x, y)\n",
    "ax1.set_title('Custom Distribution')\n",
    "ax1.set_xlabel('Days')\n",
    "ax1.set_ylabel('Conflict Zones')\n",
    "\n",
    "# Convert y values to integers\n",
    "y = [int(val) for val in y]\n",
    "\n",
    "# Create path to modified CSV file\n",
    "output_file = os.path.join(country, \"simulated-conflicts.csv\")\n",
    "\n",
    "# Call the function to generate all zeros csv file\n",
    "generate_conflict_zones_csv(output_file, conflict_zones, period)\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df_modified = pd.read_csv(output_file)\n",
    "\n",
    "# Update the modified DataFrame with the new y values\n",
    "modified_rows = []\n",
    "y_index = 0\n",
    "for _, row in df_modified.iterrows():\n",
    "    row = row.values\n",
    "    if y_index >= len(y):\n",
    "        break\n",
    "\n",
    "    number = y[y_index]\n",
    "    y_index += 1\n",
    "    assigned_count = 0\n",
    "    for i in range(1, len(row)):\n",
    "        if assigned_count < number:\n",
    "            row[i] = 1\n",
    "            assigned_count += 1\n",
    "        else:\n",
    "            row[i] = 0\n",
    "\n",
    "    modified_rows.append(row)\n",
    "    \n",
    "# Create modified DataFrame\n",
    "modified_df = pd.DataFrame(modified_rows, columns=df.columns)\n",
    "\n",
    "# Compute the sum of each row (excluding the '#Day' column)\n",
    "sum_values = modified_df.iloc[:, 1:].sum(axis=1)\n",
    "\n",
    "# Plot the summed values\n",
    "ax2.plot(x, sum_values)\n",
    "ax2.set_title('simulated-conflicts.csv')\n",
    "ax2.set_xlabel('Days')\n",
    "\n",
    "# Save the modified DataFrame to the output file\n",
    "modified_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f'{country}/simulated-conflicts.csv created.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f8723a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
